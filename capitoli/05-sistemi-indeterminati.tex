%!TEX root = ../main.tex

\chapter{Risoluzione di sistemi lineari indeterminati}

Prendiamo un sistema lineare della forma:
\begin{equation*}
A\x =\mathbf{b}
\end{equation*}
dove $A\in \mathbb{R}^{m\times n} ,\mathbf{b} \in \mathbb{R}^{m} ,\x \in \mathbb{R}^{n}$. Il sistema si dice \textbf{indeterminato}\index{sistema!indeterminato} se $m\ne n$. In particolare:
\begin{itemize}
\item \textbf{sovradeterminato}\index{sistema!sovradeterminato} se $m >n$,
\item \textbf{sottodeterminato}\index{sistema!sottodeterminato} se $m< n$.
\end{itemize}

\section{Sistemi lineari sovradeterminati}
Approfondiremo ora i sistemi sovradeterminati, caso di maggiore interesse.
Sia dunque $A\in \mathbb{R}^{m\times n} ,m\geqslant n$.
Consideriamo il sistema lineare
\begin{equation}
A\x =\mathbf{b} ,\qquad\mathbf{b} \in \mathbb{R}^{m},
\label{eq:sist-lin-sovradet}
\end{equation}
osserviamo che \eqref{eq:sist-lin-sovradet} ha soluzione nel senso classico del termine solo se il termine noto è un elemento del seguente spazio:
\begin{equation*}
\operatorname{range}(A) =\left\{\y \in \mathbb{R}^{m} \ \text{tale che} \ A\x =\y \ \text{per qualche} \ \x \in \mathbb{R}^{n}\right\}.
\end{equation*}
Dobbiamo quindi allargare il concetto di \textit{soluzione} per studiare un sistema sovradeterminato.
\begin{definition}
[Soluzione di un sistema lineare nel senso dei minimi quadrati]
\index{soluzione!ai minimi quadrati}
Dati $A\in \mathbb{R}^{m\times n}$, $m\geqslant n$, e $\mathbf{b} \in \mathbb{R}^{m}$, diciamo che $\x^{\star } \in \mathbb{R}^{n}$ è soluzione di \eqref{eq:sist-lin-sovradet} nel senso dei minimi quadrati se
\begin{equation*}
\Phi \left(\x^{\star }\right) =\min_{\x \in \mathbb{R}^{n}} \Phi (\x),
\end{equation*}
dove il funzionale da minimizzare è $\Phi (\mathbf{w}) =\Vert A\mathbf{w} -\mathbf{b}\Vert ^{2}_{2}$, il residuo nella norma euclidea.
\end{definition}
\textit{Osservazione.} Se $m=n$, la soluzione $\x^{\star }$ nel senso dei minimi quadrati coincide con la soluzione classica perché $\Phi \left(\x^{\star }\right) =0$.

Dobbiamo chiarire se la soluzione ai minimi quadrati esista e se sia unica.
\begin{lemma}
Se la soluzione $\x^{\star }$ nel senso dei minimi quadrati di un sistema lineare esiste, essa coincide con la soluzione $\x^{\star }$ nel senso classico del \textit{sistema di equazioni normali}:
\begin{equation*}
A^{T} A\x^{\star } =A^{T}\mathbf{b}.
\end{equation*}
\end{lemma}
\textit{Dimostrazione.}
Scriviamo il funzionale da minimizzare:
\begin{align*}
\Phi (\x) & =\Vert A\x -\mathbf{b}\Vert ^{2}_{2}\\
 & =( A\x -\mathbf{b})^{T}( A\x -\mathbf{b})\\
 & =\left(( A\x)^{T} -\mathbf{b}^{T}\right)( A\x -\mathbf{b})\\
 & =( A\x)^{T} A\x-\underbrace{\mathbf{b}^{T}A\x}_{\langle \mathbf{b} ,A\x \rangle } -\underbrace{( A\x)^{T}\mathbf{b}}_{\langle A\x ,\mathbf{b} \rangle } +\mathbf{b}^{T}\mathbf{b}\\
 & =\x^{T} A^{T} A\x -2( A\x)^{T}\mathbf{b} +\mathbf{b}^{T}\mathbf{b}\\
 & =\x^{T} A^{T} A\x -2\x^{T} A^{T}\mathbf{b} +\mathbf{b}^{T}\mathbf{b}.
\end{align*}
Calcoliamone poi il gradiente
\begin{equation*}
\nabla \Phi (\x) =2A^{T} A\x -2A^{T}\mathbf{b}
\end{equation*}
e poniamolo uguale a zero per trovare il minimo:
\begin{gather*}
\nabla \Phi \left(\x^{\star }\right) =0\\
\Updownarrow \\
A^{T} A\x^{\star } -A^{T}\mathbf{b} =0\\
\Updownarrow \\
A^{T} A\x^{\star } =A^{T}\mathbf{b}.
\end{gather*}
\begin{theorem}
Sia $A\in \mathbb{R}^{m\times n}$, $m\geqslant n$.
Se $A$ ha rango pieno, cioè $\operatorname{rank}(A) =n$, allora $A^{T} A\in \mathbb{R}^{n\times n}$ è una matrice SDP e quindi il sistema di equazioni normali
\begin{equation*}
A^{T} A\x^{\star } =A^{T}\mathbf{b}
\end{equation*}
ammette una e una sola soluzione.
\end{theorem}
\textit{Osservazioni.}
\begin{itemize}
    \item Se $A^{T} A\x^{\star } =A^{T}\mathbf{b}$ ammette una e una sola soluzione in senso classico, allora \eqref{eq:sist-lin-sovradet} ammette una e una sola soluzione nel senso dei minimi quadrati.
    \item In genere, la matrice $A^{T} A$ è molto mal condizionata, quindi nella pratica è spesso difficile risolvere il sistema di equazioni normali per calcolare $\x^{\star }$.
    \item Se una matrice $A$ invertibile viene rappresentata in un calcolatore, a causa degli errori di arrotondamento è possibile che $A^TA$ perda l'invertibilità. Ad esempio,
    \[
        A = \begin{bmatrix}
            1 & 1 \\
            2^{-27} & 0 \\
            0 & 2^{-27}
        \end{bmatrix},\quad \operatorname{float}(A^T A)=\begin{bmatrix}
            1 & 1\\
            1 & 1
        \end{bmatrix}
    \]
\end{itemize}
Dobbiamo quindi trovare un altro modo di procedere per la risoluzione.
\subsection{Fattorizzazione QR}
Proviamo a generalizzare il concetto di fattorizzazione $LU$, visto nella sezione \ref{sec:fattorizzazione-lu} e proprio delle matrici quadrate, anche a matrici rettangolari come $A$.
\begin{definition}
[Fattorizzazione $QR$]
\index{fattorizzazione!QR}
Sia $A\in \mathbb{R}^{m\times n}$, $m\geqslant n$.
Si dice che $A$ ammette una fattorizzazione $QR$ se esistono:
\begin{itemize}
\item $Q\in \mathbb{R}^{m\times m}$ ortogonale ($Q^{-1} =Q^{T}$);
\item $R\in \mathbb{R}^{m\times n}$ trapezoidale superiore (con le righe dalla $n+1$ in poi tutte nulle) 
\end{itemize}
tali che $$A=QR$$
\end{definition}
\begin{equation*}
\underbrace{\begin{bmatrix}
\cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot
\end{bmatrix}}_{A\in \mathbb{R}^{m\times n}} =\underbrace{\begin{bmatrix}
\cdot  & \cdot  & \cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot  & \cdot  & \cdot
\end{bmatrix}}_{Q\in \mathbb{R}^{m\times m}}\underbrace{\begin{bmatrix}
\cdot  & \cdot  & \cdot \\
0 & \cdot  & \cdot \\
0 & 0 & \cdot \\
0 & 0 & 0\\
0 & 0 & 0
\end{bmatrix}}_{R\in \mathbb{R}^{m\times n}}
\end{equation*}
\textbf{Proprietà (Fattorizzazione }$QR$\textbf{ ridotta).} \index{fattorizzazione!QR!ridotta} Sia $A\in \mathbb{R}^{m\times n}$, $m\geqslant n$, di rango massimo di cui esista la fattorizzazione $QR$. Allora esiste un'unica fattorizzazione di $A$ tale che:
\begin{equation*}
A=\tilde{Q} \ \tilde{R}
\end{equation*}
dove $\tilde{Q}$ e $\tilde{R}$ sono le sottomatrici ottenute da $Q$ e $R$ nel seguente modo:
\begin{itemize}
\item $\tilde{Q} =Q( 1:m,1:n) \in \mathbb{R}^{m\times n}$;
\item $\tilde{R} =R( 1:n,1:n) \in \mathbb{R}^{n\times n}$.
\end{itemize}

Inoltre le colonne di $\tilde{Q}$ sono vettori ortonormali e $\tilde{R}$ coincide con il fattore di Cholesky della matrice $A^{T} A$, ossia $A^{T} A=\tilde{R}^{T}\tilde{R}$.
\begin{equation*}
\underbrace{\begin{bmatrix}
\cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot
\end{bmatrix}}_{A\in \mathbb{R}^{m\times n}} =\underbrace{\begin{bmatrix}
\begin{array}{|c c c|}
\hline
\cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot \\
\cdot  & \tilde{Q} & \cdot \\
\cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot \\
\hline
\end{array} & \begin{array}{ c }
\cdot \\
\cdot \\
\cdot \\
\cdot \\
\cdot
\end{array} & \begin{array}{ c }
\cdot \\
\cdot \\
\cdot \\
\cdot \\
\cdot
\end{array}
\end{bmatrix}}_{Q\in \mathbb{R}^{m\times m}}\underbrace{\begin{bmatrix}
\begin{array}{|c c c|}
\hline
\cdot  & \cdot  & \cdot \\
0 & \tilde{R} & \cdot \\
0 & 0 & \cdot \\
\hline
\end{array}\\
\begin{array}{ c c c }
0 & 0 & 0
\end{array}\\
\begin{array}{ c c c }
0 & 0 & 0
\end{array}
\end{bmatrix}}_{R\in \mathbb{R}^{m\times n}}
\end{equation*}
Come usiamo $A=\tilde{Q} \ \tilde{R}$ per risolvere $A\x =\mathbf{b}$?
\begin{theorem}
Sia $A\in \mathbb{R}^{m\times n}$, $m\geqslant n$, di rango massimo, e sia $\mathbf{b} \in \mathbb{R}^{m}$. Allora esiste un'unica soluzione $\x^{\star } \in \mathbb{R}^{n}$ nel senso dei minimi quadrati del sistema sovradimensionato $A\x =\mathbf{b}$ ed essa è data da:
\begin{equation*}
\x^{\star } =\tilde{R}^{-1}\tilde{Q}^{T}\mathbf{b} \qquad \text{ovvero} \qquad \tilde{R}\x^{\star } =\tilde{Q}^{T}\mathbf{b}
\end{equation*}
dove $\tilde{Q}$ ed $\tilde{R}$ sono i fattori della decomposizione ridotta di $A$.
\end{theorem}
\begin{equation*}
\underbrace{\begin{bmatrix}
\begin{array}{|c c c|}
\hline
\cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot \\
\cdot  & \tilde{Q} & \cdot \\
\cdot  & \cdot  & \cdot \\
\cdot  & \cdot  & \cdot \\
\hline
\end{array} & \begin{array}{ c }
\cdot \\
\cdot \\
\cdot \\
\cdot \\
\cdot
\end{array} & \begin{array}{ c }
\cdot \\
\cdot \\
\cdot \\
\cdot \\
\cdot
\end{array}
\end{bmatrix}}_{Q\in \mathbb{R}^{m\times m}}\underbrace{\begin{bmatrix}
\begin{array}{|c c c|}
\hline
\cdot  & \cdot  & \cdot \\
0 & \tilde{R} & \cdot \\
0 & 0 & \cdot \\
\hline
\end{array}\\
\begin{array}{ c c c }
0 & 0 & 0
\end{array}\\
\begin{array}{ c c c }
0 & 0 & 0
\end{array}
\end{bmatrix}}_{R\in \mathbb{R}^{m\times n}}\underbrace{\begin{bmatrix}
\begin{array}{ c }
\cdot \\
\cdot \\
\cdot
\end{array}
\end{bmatrix}}_{\x \in \mathbb{R}^{n}} =\underbrace{\begin{bmatrix}
\begin{array}{ c }
\cdot \\
\cdot \\
\cdot \\
\cdot \\
\cdot
\end{array}
\end{bmatrix}}_{\mathbf{b} \in \mathbb{R}^{n}}
\end{equation*}
\textit{Idea di dimostrazione.} Ci concentreremo sulla dimostrazione dell'esistenza, tralasciando quella dell'unicità. Supponendo che $A$ ammetta una fattorizzazione $QR$, allora:
\begin{align*}
\Vert A\x -\mathbf{b}\Vert ^{2}_{2} & =\Vert QR\x -\mathbf{b}\Vert ^{2}_{2} & \\
 & =\left\Vert Q^{T} QR\x -Q^{T}\mathbf{b}\right\Vert ^{2}_{2} & \Vert \mathbf{z}\Vert _{2} =\left\Vert Q^{T}\mathbf{z}\right\Vert _{2} \ \forall \mathbf{z}\\
 & =\left\Vert R\x -Q^{T}\mathbf{b}\right\Vert ^{2}_{2} & \text{($Q$ è ortogonale)}\\
 & =\left\Vert \tilde{R}\x -\tilde{Q}^{T}\mathbf{b}\right\Vert ^{2}_{2} +\sum ^{m}_{i=n+1}\left[\left( Q^{T}\mathbf{b}\right)_{i}\right]^{2} & \forall \x \in \mathbb{R}^{n}.
\end{align*}
Osserviamo in particolare l'ultimo passaggio: abbiamo la norma (al quadrato, ma ciò è irrilevante) di un vettore, ovvero $R\x -Q^{T}\mathbf{b}$. Dato che la norma $2$ al quadrato è per definizione (vedi \ref{def:norma-vettore}) la somma delle componenti al quadrato, possiamo liberamente separare in due somme.
Il termine $R\x$ si separa in $\tilde{R}\x$ e una somma di zeri.
Il termine $Q^{T}\mathbf{b}$ si separa in $\tilde{Q}^{T}\mathbf{b}$ e il termine in sommatoria (si noti l'indice che va da $n+1$ a $m$).
Il minimo di $\Phi (\x)$ è raggiunto per $\x^{\star }$ che annulla tutto il termine in cui compare:
\begin{equation*}
\tilde{R}\x -\tilde{Q}^{T}\mathbf{b} =0\ \ \Rightarrow \ \ \left\Vert \tilde{R}\x -\tilde{Q}^{T}\mathbf{b}\right\Vert =0
\end{equation*}
e dunque $\x^{\star }$ soddisfa
\begin{gather*}
\tilde{R}\x^{\star } -\tilde{Q}^{T}\mathbf{b} =0\ \ \Rightarrow \ \ \x^{\star } =\tilde{R}^{-1}\tilde{Q}^{T}\mathbf{b}.
\qed
\end{gather*}
\textit{Osservazione.} Il costo di calcolare la fattorizzazione $QR$ è $\approx mn^{2}$. L'algoritmo per il calcolo di $Q$ è basato sull'algoritmo di Gram-Schmidt, la tecnica dall'algebra lineare per la costruzione di una base ortogonale.

\section{Sistemi lineari sottodeterminati}
%TODO